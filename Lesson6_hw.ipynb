{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d582f57",
   "metadata": {},
   "source": [
    "# Введение в обработку естественного языка\n",
    "## Урок 6. Классификация текста. Анализ тональности текста\n",
    "Классификация текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03100a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"train.tsv\", delimiter=\"\\t\")\n",
    "test_df = pd.read_csv(\"test.tsv\", delimiter=\"\\t\")\n",
    "\n",
    "print('Train size = {}'.format(len(train_df)))\n",
    "print('Test size = {}'.format(len(test_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737cf0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec39c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = 'love', 'great', 'best', 'wonderful' \n",
    "negative_words = 'worst', 'awful', '1/10', 'crap' \n",
    "\n",
    "positives_count = test_df.review.apply(lambda text: sum(word in text for word in positive_words))\n",
    "negatives_count = test_df.review.apply(lambda text: sum(word in text for word in negative_words))\n",
    "is_positive = positives_count > negatives_count\n",
    "correct_count = (is_positive == test_df.is_positive).values.sum()\n",
    "\n",
    "accuracy = correct_count / len(test_df)\n",
    "\n",
    "print('Test accuracy = {:.2%}'.format(accuracy))\n",
    "if accuracy > 0.71:\n",
    "    from IPython.display import Image, display\n",
    "    display(Image('https://s3.amazonaws.com/achgen360/t/rmmoZsub.png', width=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5483af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile('<br />')\n",
    "\n",
    "print(pattern.subn(' ', train_df['review'].iloc[3])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0877339",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['review'] = train_df['review'].apply(lambda text: pattern.subn(' ', text)[0])\n",
    "test_df['review'] = test_df['review'].apply(lambda text: pattern.subn(' ', text)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d1de59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replase_words(text,dict_): \n",
    "    output = ''\n",
    "    for word in text.split(' '):\n",
    "        word = word.strip()\n",
    "        if word in dict_.keys(): \n",
    "            output += ' ' + dict_[word]\n",
    "        else:\n",
    "            output += ' ' + word\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae01bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(\"@[\\w]*\",\"\",text)\n",
    "    text = replase_words(text, emoticon_dict)\n",
    "    text = replase_words(text, apostrophe_dict)\n",
    "    text = replase_words(text, short_word_dict)\n",
    "    text = re.sub(\"[^\\w\\s]\",\" \",text)\n",
    "    text = re.sub(\"[^a-zA-Z0-9\\_]\",\" \",text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b321fee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['review'] = train_df['review'].apply(lambda x: clean_text(x))\n",
    "test_df['review'] = test_df['review'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0638909",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc60c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "dummy_data = ['The movie was excellent',\n",
    "              'the movie was awful']\n",
    "\n",
    "dummy_matrix = vectorizer.fit_transform(dummy_data)\n",
    "\n",
    "print(dummy_matrix.toarray())\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674f0b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(train_df['review'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12267a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.transform([train_df['review'].iloc[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a375d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "dummy_data = ['The movie was excellent',\n",
    "              'the movie was awful']\n",
    "dummy_labels = [1, 0]\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "model = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('classifier', classifier)\n",
    "])\n",
    "\n",
    "model.fit(dummy_data, dummy_labels)\n",
    "\n",
    "print(vectorizer.get_feature_names())\n",
    "print(classifier.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc240c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_df['review'], train_df['is_positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43ab202",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def eval_model(model, test_df):\n",
    "    preds = model.predict(test_df['review'])\n",
    "    print('Test accuracy = {:.2%}'.format(accuracy_score(test_df['is_positive'], preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4708e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model(model, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4966c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install eli5==0.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1027e1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "eli5.show_weights(classifier, vec = vectorizer, top = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486f7867",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Positive' if test_df['is_positive'].iloc[1] else 'Negative')\n",
    "eli5.show_prediction(classifier, test_df['review'].iloc[1], vec=vectorizer, \n",
    "                     targets=['positive'], target_names=['negative', 'positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7843c4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Positive' if test_df['is_positive'].iloc[6] else 'Negative')\n",
    "eli5.show_prediction(classifier, test_df['review'].iloc[6], vec=vectorizer, \n",
    "                     targets=['positive'], target_names=['negative', 'positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6993e752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "preds = model.predict(test_df['review'])\n",
    "incorrect_pred_index = np.random.choice(np.where(preds != test_df['is_positive'])[0])\n",
    "\n",
    "eli5.show_prediction(classifier, test_df['review'].iloc[incorrect_pred_index],\n",
    "                     vec=vectorizer, targets=['positive'], target_names=['negative', 'positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35e14f0",
   "metadata": {},
   "source": [
    "### Проверьте повысилось ли качество на стандартных подходах при лемматизации/и без неё"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd940dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c016eb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\", disable=[\"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffa55b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    tokens=[token.lemma_.strip() for token in doc]\n",
    "    text=\" \".join(tokens)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988f24bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lem_df = train_df\n",
    "test_lem_df = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd82587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lem_df['review'] = train_lem_df['review'].progress_apply(lambda x: lemmatize_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9135aae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lem_df['review'] = test_lem_df['review'].progress_apply(lambda x: lemmatize_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37e5cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lem_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60a17e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_docs.pkl', 'wb') as f:\n",
    "    pickle.dump(train_lem_df,f)\n",
    "    \n",
    "with open('test_docs.pkl', 'wb') as f: \n",
    "    pickle.dump(test_lem_df,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36a3d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_docs.pkl', 'rb') as f:\n",
    "    train_lem_df = pickle.load(f)\n",
    "    \n",
    "with open('test_docs.pkl', 'rb') as f:\n",
    "    test_lem_df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d7f922",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lem_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ccf152",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "model = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('classifier', classifier)\n",
    "])\n",
    "\n",
    "model.fit(train_lem_df['review'], train_lem_df['is_positive'])\n",
    "\n",
    "eval_model(model, test_lem_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0613318",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1, 2), max_features=20000, analyzer='word')\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "model = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('classifier', classifier)\n",
    "])\n",
    "\n",
    "model.fit(train_lem_df['review'], train_lem_df['is_positive'])\n",
    "\n",
    "eval_model(model, test_lem_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634c8fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c221466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagging_text(text):\n",
    "    doc = nlp(text)\n",
    "    tokens=[token.ent_type_.strip() if token.ent_type_ !=\"\" else token.text.strip() for token in doc ]\n",
    "\n",
    "    text = [tokens[i] for i in range(1, len(tokens)) if tokens[i] != tokens[i-1] ]\n",
    "    text=\" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fa8df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tag_df = train_lem_df\n",
    "test_tag_df = test_lem_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3aa8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tag_df['review'] = train_tag_df['review'].progress_apply(lambda x: tagging_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedc8968",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tag_df['review'] = test_tag_df['review'].progress_apply(lambda x: tagging_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c09433d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tag_df['review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808a5fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_tags.pkl', 'wb') as f:\n",
    "    pickle.dump(train_tag_df,f)\n",
    "    \n",
    "with open('test_tags.pkl', 'wb') as f: \n",
    "    pickle.dump(test_tag_df,f)\n",
    "    \n",
    "with open('train_tags.pkl', 'rb') as f:\n",
    "    train_tag_df = pickle.load(f)\n",
    "    \n",
    "with open('test_tags.pkl', 'rb') as f:\n",
    "    test_tag_df = pickle.load(f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a9aee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "model = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('classifier', classifier)\n",
    "])\n",
    "\n",
    "model.fit(train_tag_df['review'], train_tag_df['is_positive'])\n",
    "\n",
    "eval_model(model, test_tag_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a6bd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1, 2), max_features=20000, analyzer='word')\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "model = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('classifier', classifier)\n",
    "])\n",
    "\n",
    "model.fit(train_tag_df['review'], train_tag_df['is_positive'])\n",
    "\n",
    "eval_model(model, test_tag_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e38976",
   "metadata": {},
   "source": [
    "### Запустите классификатор и модельки на сеточках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fff73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalMaxPooling1D, Dropout, Conv1D, BatchNormalization, MaxPooling1D#, GlobalAveragePooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ba3099",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "words_counter = Counter((word for text in train_tag_df.review for word in text.lower().split()))\n",
    "\n",
    "word2idx = {\n",
    "    '': 0,\n",
    "    '<unk>': 1\n",
    "}\n",
    "for word, count in words_counter.most_common():\n",
    "    if count < 10:\n",
    "        break\n",
    "        \n",
    "    word2idx[word] = len(word2idx)\n",
    "    \n",
    "print('Words count', len(word2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a673a39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(texts, word2idx, max_text_len):\n",
    "    data = np.zeros((len(texts), max_text_len), dtype=np.int)\n",
    "    \n",
    "    for inx, text in enumerate(texts):\n",
    "        result = []\n",
    "        for word in text.split():\n",
    "            if word in word2idx:\n",
    "                result.append(word2idx[word])\n",
    "        padding = [0]*(max_text_len - len(result))\n",
    "        data[inx] = np.array(padding + result[-max_text_len:], dtype=np.int)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2198f0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = convert(train_tag_df.review, word2idx, 1000)\n",
    "X_test = convert(test_tag_df.review, word2idx, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7292ea3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=len(word2idx), output_dim=256, input_shape=(X_train.shape[1],)),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(units=256, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(units=128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b210bb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, train_tag_df.is_positive, batch_size=1024, epochs=5, \n",
    "          validation_data=(X_test, test_tag_df.is_positive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740d9c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, test_tag_df.is_positive, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a141e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = convert(train_lem_df.review, word2idx, 1000)\n",
    "X_test = convert(test_lem_df.review, word2idx, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3f545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(input_dim=len(word2idx), output_dim=256, input_shape=(X_train.shape[1],)),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(units=256, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(units=128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5483506",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, train_lem_df.is_positive, batch_size=1024, epochs=5, \n",
    "          validation_data=(X_test, test_lem_df.is_positive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c925c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, test_lem_df.is_positive, batch_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c20bb7",
   "metadata": {},
   "source": [
    "Модель на токенезированном датасете лучше, чем только лемматизация."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a67cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
