{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f98983b0",
   "metadata": {},
   "source": [
    "# Введение в обработку естественного языка\n",
    "## Урок 12. Модель Transformer-2\n",
    "Задание\n",
    "Реализовать суммаризацию текста\n",
    "Взять тот же датасет, который был на вебинаре и предобученную модель для задачи суммаризации\n",
    "Проверить насколько хорошо она суммаризирует\n",
    "2.(дополнительно) Сделать генерацию заголовков для статьи (обучить модель для генерации заголовков)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1da7198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /home/alexey/anaconda3/envs/tftest/lib/python3.10/site-packages (from transformers) (23.0)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.12.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/alexey/anaconda3/envs/tftest/lib/python3.10/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/alexey/anaconda3/envs/tftest/lib/python3.10/site-packages (from transformers) (1.24.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/alexey/anaconda3/envs/tftest/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (682 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m682.2/682.2 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.14.1\n",
      "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/alexey/anaconda3/envs/tftest/lib/python3.10/site-packages (from transformers) (2.28.2)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2023.5.0-py3-none-any.whl (160 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.1/160.1 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /home/alexey/anaconda3/envs/tftest/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/alexey/anaconda3/envs/tftest/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/alexey/anaconda3/envs/tftest/lib/python3.10/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/alexey/anaconda3/envs/tftest/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/alexey/anaconda3/envs/tftest/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Installing collected packages: tokenizers, sentencepiece, pyyaml, fsspec, filelock, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.12.0 fsspec-2023.5.0 huggingface-hub-0.15.1 pyyaml-6.0 sentencepiece-0.1.99 tokenizers-0.13.3 transformers-4.29.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef6053fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.15.2-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/alexey/anaconda3/envs/tftest/lib/python3.10/site-packages (from torch) (3.12.0)\n",
      "Requirement already satisfied: jinja2 in /home/alexey/anaconda3/envs/tftest/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.0.0\n",
      "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sympy\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /home/alexey/anaconda3/envs/tftest/lib/python3.10/site-packages (from torch) (4.4.0)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting networkx\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel in /home/alexey/anaconda3/envs/tftest/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: setuptools in /home/alexey/anaconda3/envs/tftest/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (67.5.1)\n",
      "Collecting lit\n",
      "  Downloading lit-16.0.5.post0.tar.gz (138 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.1/138.1 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting cmake\n",
      "  Using cached cmake-3.26.3-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.0 MB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/alexey/anaconda3/envs/tftest/lib/python3.10/site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: numpy in /home/alexey/anaconda3/envs/tftest/lib/python3.10/site-packages (from torchvision) (1.24.2)\n",
      "Requirement already satisfied: requests in /home/alexey/anaconda3/envs/tftest/lib/python3.10/site-packages (from torchvision) (2.28.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/alexey/anaconda3/envs/tftest/lib/python3.10/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/alexey/anaconda3/envs/tftest/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/alexey/anaconda3/envs/tftest/lib/python3.10/site-packages (from requests->torchvision) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/alexey/anaconda3/envs/tftest/lib/python3.10/site-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/alexey/anaconda3/envs/tftest/lib/python3.10/site-packages (from requests->torchvision) (2022.12.7)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: lit\n",
      "  Building wheel for lit (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-16.0.5.post0-py3-none-any.whl size=88253 sha256=b8655fd50bbed0c9289b2bcf0fb335095bef2c63d0a6b58cc325b68e419824c6\n",
      "  Stored in directory: /home/alexey/.cache/pip/wheels/1a/24/92/1e1c9e37be8411a7c7c18a4c54962f5d0a75c56bab4a6f7f57\n",
      "Successfully built lit\n",
      "Installing collected packages: mpmath, lit, cmake, sympy, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, networkx, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchvision\n",
      "Successfully installed cmake-3.26.3 lit-16.0.5.post0 mpmath-1.3.0 networkx-3.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 sympy-1.12 torch-2.0.1 torchvision-0.15.2 triton-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "111065ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexey/anaconda3/envs/tftest/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f68b08a-0275-4127-bc00-6802e92c0bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv /home/alexey/Downloads/gazeta_train.jsonl ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30ea0c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gazeta_records(file_name, shuffle=True, sort_by_date=False):\n",
    "    assert shuffle != sort_by_date\n",
    "    records = []\n",
    "    with open(file_name,\"r\",encoding=\"utf-8\") as r:\n",
    "        for line in r:\n",
    "            records.append(json.loads(line))\n",
    "    if sort_by_date:\n",
    "        records.sort(key=lambda x: x[\"date\"])\n",
    "    if shuffle:\n",
    "        random.shuffle\n",
    "    return records\n",
    "\n",
    "def summurize(rec):\n",
    "    article_text = (\"{}\".format(test_records[rec][\"text\"]))\n",
    "    input_ids = tokenizer([HANDLER(article_text)], \n",
    "                          return_tensors=\"pt\", \n",
    "                          padding=\"max_length\", \n",
    "                          truncation=True, \n",
    "                          max_length=512)[\"input_ids\"]\n",
    "    output_ids = model.generate(input_ids=input_ids,\n",
    "                                max_length=84,\n",
    "                                no_repeat_ngram_size=2,\n",
    "                                num_beams=4)[0]\n",
    "    summary = tokenizer.decode(output_ids,skip_special_tokens=True,clean_up_tokenization_spaces=False)\n",
    "    print('TEXT:   ', article_text)\n",
    "    print('SUMMARY:', summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24436694",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_records = read_gazeta_records(\"gazeta_test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f502a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|██████████| 375/375 [00:00<00:00, 982kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 730/730 [00:00<00:00, 1.68MB/s]\n",
      "Downloading spiece.model: 100%|██████████| 4.31M/4.31M [00:00<00:00, 9.83MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 65.0/65.0 [00:00<00:00, 151kB/s]\n",
      "/home/alexey/anaconda3/envs/tftest/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:454: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Downloading pytorch_model.bin: 100%|██████████| 2.33G/2.33G [00:47<00:00, 49.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "HANDLER = lambda k: re.sub('\\s+', ' ', re.sub('\\n+', ' ', k.strip()))\n",
    "model_name = \"csebuetnlp/mT5_multilingual_XLSum\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48396d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-04 18:11:13.095812: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT:    Около 11 тысяч зрителей увидели все самое лучшее, что есть на сегодняшний день в культуре Бурятии. В Кремле выступил Бурятский государственный академический театр оперы и балета, Национальный цирк, Бурятский национальный театр песни и танца «Байкал», ставший победителем шоу «Танцуют все!» на телеканале «Россия», а также другие профессиональные и самодеятельные коллективы региона. Более 300 артистов из одного региона на главной сцене страны - похоже это рекорд России. Зрителям рассказали, что Республике Бурятия, чье население составляет 1 миллион человек, сохранилась и развивается культура десятков национальностей, включая русских, бурятов, староверов (семейских), эвенков. И все они были представлены в Москве. Как писали после шоу зрители в соцсетях: «А мы думали, что в Бурятии только буряты живут…». Для неподготовленного зрителя это вообще были вечера открытий. Например, когда еще в Кремлевском дворце выстраивалась очередь из желающих попасть на прием к врачам-пульсологам и ламам-астрологам? А между тем буквально в паре метров можно было увидеть выставку Национального музея Бурятии о культуре и быте бурятского народа. И она не менее уникальна, чем китайская, или монгольская времен Чингисхана. И там же современное искусство, например, знаменитые работы скульптора Даши Намдакова. Не обошлось без политической составляющей. Перед началом праздничного шоу с главной сцены страны первый заместитель руководителя администрации президента России Сергей Кириенко зачитал поздравление президента Российской Федерации Владимира Путина , в котором говорилось: «Сердечно поздравляю вас с наступлением Нового года по лунному календарю и с наступлением Белого месяца! Этот светлый, особо почитаемый последователями буддизма праздник символизирует обновление природы, стремление человека к гармонии и чистоте помыслов. Он обращает верующих к духовным и нравственным истокам этой древней религии, ее непреходящим устоям и ценностям. Важно, что российские буддисты бережно хранят и передают из поколения в поколение традиции предков…». Заместитель председателя правительства России , полномочный представитель президента РФ в ДФО Юрий Трутнев , видимо, также был удивлен ажиотажем и аншлагом в Кремле и рассказал журналистам: «Я спросил у [главы Бурятии] Алексея Цыденова, сколько людей приехало из Бурятии на праздник, и он ответил: «Тысяча из шести». Это значит, что большая часть людей на празднике — из Москвы, значит, им это интересно!». Сам же Цыденов в своем выступлении посетовал на то, что в России все же мало что знают о Бурятии и ее традициях, но был оптимистичен: «Республика Бурятия богата своей историей, своими традициями. Наша цель — показать все возможности и огромный потенциал республики, чтобы не только жители Бурятии, но и вся Россия гордилась достижениями нашего народа. Мы хотим, чтобы жители всей России знали, что есть такая жемчужина — Бурятия». Небольшим, отдаленным и дотационным регионам всегда непросто быть замеченными властями. А их губернаторам и главам сложно быть ближе к высшему руководству страны по сравнению с их коллегами из более богатых субъектов. Но, похоже, главе Бурятии Алексею Цыденову удается переломить эту не самую приятную для многих регионов традицию. Цыденов пришел в Бурятию с поста замминистра транспорта России без опыта управления регионом. Но за три года сумел стать опытным региональным политиком, способным на неожиданные ходы. Как пример, нынешние посвященные Восточному новому году концерты в Москве. Пока другие регионы со своими местными праздниками и юбилеями стоят в очереди, чтобы «затащить» к себе руководителей страны на торжества, Цыденов, наоборот, сумел привезти свой регион в Москву. Причем не куда-нибудь, а в самый Кремль. Таким образом, всего за два столичных дня Бурятия решила сразу несколько задач, в том числе подтвердила свой статус буддийского лидера России и познакомила жителей всей страны со своей богатой культурой. Зрители после концерта отвечали Бурятии взаимностью. Можно обратить внимание лишь на некоторые высказанные в соцсетях мнения об увиденном в кремлевском дворце: «Люди в Бурятии очень талантливые», «Вот это красота! Срочно летим в Бурятию», «Буряты, вы крутые!», «Бурятия, мы вам завидуем!».\n",
      "SUMMARY: В воскресенье в Москве состоялось праздничное шоу, на котором можно было увидеть все самое лучшее, что есть на сегодняшний день в культуре Бурятии.\n"
     ]
    }
   ],
   "source": [
    "summurize(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a760c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT:    Самые известные российские пранкеры Владимир «Вован» Кузнецов и Алексей «Лексус» Столяров, на счету которых множество розыгрышей мировых политиков первого эшелона, позвонили члену конгресса США от Демократической партии Максин Уотерс от имени шведской школьницы, экологической активистки Греты Тунберг и ее отца Сванте. Звонок был сделан в рамках нового анимационного шоу пранкеров Stars save the Earth. Россияне рассказали американскому политику, что Грета якобы сейчас участвует в митинге в штате Северная Каролина «в поддержку экологии острова Чунга-Чанга». В этой связи «Тунберги» предложили Уотерс также поддержать экологию острова (несуществующего), чтобы ее речь затем якобы транслировать на мероприятии, передает РИА «Новости». «Я очень рада, что Грета с вами в Северной Каролине, где вы сосредоточены на защите очень важного острова Чунга-Чанга. Самое главное сейчас — убедиться, что остров защищен, что вы даете ему всю поддержку, которую вы можете дать», — заявила конгрессвумен США. «Отец Греты» также рассказал Уотерс, что его дочь лишилась сна и аппетита из-за того, что глава Белого дома Дональд Трамп не подписал Парижское соглашение по климату. «Я крикнула ему, чтобы он подписал Парижское соглашение по климату. Он подошел ко мне, наклонился и тихо сказал: «Послушай меня внимательно, маленькая девочка, ты никогда не добьешься своей цели, как и те дураки из конгресса, которые пытаются обвинить меня», — якобы рассказала Грета по секрету Уотерс о том, что произошло на недавней Генеральной ассамблее ООН в Нью-Йорке. Более того, «Тунберги» на совершенно секретной основе поведали Уотерс о том, что имеют компромат на президента США — записанные на диктофон слова Трампа о том, что его будущий конкурент на президентских выборах в этом году, бывший вице-президент США Джозеф Байден «пойдет под суд вместе с шайкой экологов и демократов », для которых уже приготовлены «отдельные камеры». Услышав такое сенсационное признание, Уотерс предложила Грете выступить с обличительной речью против Трампа в конгрессе. «Мы собираемся испробовать все, что у нас есть, чтобы объявить ему импичмент», — подчеркнула демократ. Несколько дней назад Байден заявил, что будет подчиняться любой повестке, в том числе вызову в сенат для дачи показаний по делу об импичменте Трампа. «Прежде всего, я собираюсь подчиниться любой повестке, которая будет мне отправлена», — сказал Байден во время своего выступления в Фэрфилде. Бывший вице-президент неожиданно сменил свою риторику после того, как в субботу, 28 декабря, он отказался давать показания республиканцам в сенате. Тогда Байден отметил, что импичмент касается только Трампа. «Я не собираюсь делать вид, что в повестках республиканцев есть какие-либо правовые основания для моих показаний по делу об импичменте. Этот импичмент касается поведения Трампа, а не моего», — написал бывший вице-президент США в Twitter. Байден — один из потенциальных кандидатов в президенты от Демократической партии. Согласно опросу CNN от 19 декабря, Байден лидирует в предвыборной гонке демократов, его рейтинг составляет 26%. При этом этот показатель на 6% больше его ближайшего конкурента — сенатора от штата Вермонт Берни Сандерса. Байден фактически напрямую связан с запуском процедуры импичмента в отношении Трампа в палате представителей. В сентябре демократы в нижней палате конгресса организовали расследование из-за жалобы сотрудника разведки, который уличил президента США в давлении на Украину. Разведчик утверждал, что Трамп якобы потребовал от Киева начать разбирательства в отношении компании Burisma в обмен на военную помощь США. В совет правления фирмы входил сын Байдена Хантер, который также должен был стать объектом расследования. Демократы в конгрессе расценили действия Трампа как попытку найти компромат на своего вероятного соперника на выборах 2020 года, поэтому и запустили импичмент в нижней палате конгресса США. Впоследствии палата представителей предъявила обвинение Трампу по двум статьям — злоупотребление властью и препятствование расследованию. В феврале 2017 года те же пранкеры уже разыгрывали Уотерс по телефону, сообщив от имени тогдашнего украинского премьер-министра Владимира Гройсмана о «вмешательстве Москвы во внутренние дела страны Лимпопо». Вован и Лексус пожаловались конгрессвумен, что власть в стране захватил доктор Айболит. Уотерс купилась на розыгрыш, пообещав разобраться в ситуации. «Если что, США будут на вашей стороне, ребята. И эти новые вторжения в эти места… Я не знаю, сколько у нас там людей из наших разведывательных ведомств, но нам нужно больше информации по этому поводу», — заявила Уотерс. Несколькими месяцами ранее Вован и Лексус дозвонились до министра энергетики США Рика Перри. Представившись опять же Владимиром Гройсманом , пранкеры более 20 минут беседовали с Перри о санкциях в отношении России и ценах на американский уголь для Украины. Под конец разговора Кузнецов и Столяров начали откровенно разыгрывать американского министра, заявив, что тогдашний президент Украины Петр Порошенко лично изобрел новый вид биологического топлива, для изготовления которого необходимо смешивать самогон и навоз. Но даже тогда Перри не заметил подвоха и невозмутимо ответил, что будет ждать ближайшей возможности встретиться с сенатором Джоном Маккейном для обсуждения этого вопроса. Перри также пообещал лично опробовать инновационное топливо.\n",
      "SUMMARY: Российские пранкеры рассказали конгрессу США о том, что их дочь Грета Тунберг якобы участвует в митинге в Северной Каролине в поддержку экологии острова Чунга-Чанга.\n"
     ]
    }
   ],
   "source": [
    "summurize(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7871b35e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tftest]",
   "language": "python",
   "name": "conda-env-tftest-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
